{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e5fa630826a54e9894b646ba91960dca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_49541d56953541009d8dd2c47b631560",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f2804126f7274540b1bfb2aff4a5fe83",
              "IPY_MODEL_cf5aee74e58348bc868d93d487fd83f9"
            ]
          }
        },
        "49541d56953541009d8dd2c47b631560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2804126f7274540b1bfb2aff4a5fe83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5ac526f101de4762a76494d7931a7396",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 25000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 25000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46d1f6c27f574ac1a7dc58c0edc4f675"
          }
        },
        "cf5aee74e58348bc868d93d487fd83f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4d0807fd29d34c868f7b3735ea81da38",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25000/25000 [00:01&lt;00:00, 13095.15it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ea3fbf61d4544fb93cb21e3500a63ec"
          }
        },
        "5ac526f101de4762a76494d7931a7396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46d1f6c27f574ac1a7dc58c0edc4f675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d0807fd29d34c868f7b3735ea81da38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ea3fbf61d4544fb93cb21e3500a63ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af32980118134ddf86fbf29275bacf3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9d80148b52d14b3297fb37a67fa570b5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aa86829ad18840108cd71c23c96baa6b",
              "IPY_MODEL_71456887dc6e4af68bd6739840b583bd"
            ]
          }
        },
        "9d80148b52d14b3297fb37a67fa570b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa86829ad18840108cd71c23c96baa6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_04dbc947e8424b2abc4edd12844d71a1",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 25000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 25000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b79d3245d3ae4bc0a12bb095ae8dd341"
          }
        },
        "71456887dc6e4af68bd6739840b583bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_74b2f982ad03479ebab52f0ef6757bfd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25000/25000 [00:00&lt;00:00, 80106.83it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e4d399de01843ccb44da57eeb0d63ed"
          }
        },
        "04dbc947e8424b2abc4edd12844d71a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b79d3245d3ae4bc0a12bb095ae8dd341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74b2f982ad03479ebab52f0ef6757bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e4d399de01843ccb44da57eeb0d63ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98cb238bcbda49d1b9632e4036ed8077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_464cb792fd874834be3a17848b86f4eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cb92a60b0d5145059ec0c68337f063f8",
              "IPY_MODEL_8e11b02357684477a460fbfc4dac6f96"
            ]
          }
        },
        "464cb792fd874834be3a17848b86f4eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "cb92a60b0d5145059ec0c68337f063f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a6890e4cb78b4f9aaa4fdcc94775f213",
            "_dom_classes": [],
            "description": "Validation sanity check:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_967142ebbfa64523b190337520cc9651"
          }
        },
        "8e11b02357684477a460fbfc4dac6f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8154ecc6e574871b3ef64fd3315d3d4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [2:39:13&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f75c97de010a42f6b95353aabaed98de"
          }
        },
        "a6890e4cb78b4f9aaa4fdcc94775f213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "967142ebbfa64523b190337520cc9651": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8154ecc6e574871b3ef64fd3315d3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f75c97de010a42f6b95353aabaed98de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46b9a1bd92e6465da8d73351c51fd2f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_09632bb274c54bd5ab154e95b148a074",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3091133dab2e4e93bb2b78f19c317f99",
              "IPY_MODEL_e6fd8c0c2002436cbf249edfbfd45501"
            ]
          }
        },
        "09632bb274c54bd5ab154e95b148a074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "3091133dab2e4e93bb2b78f19c317f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b7782a6d04a745ba9a2522b08eb8bfca",
            "_dom_classes": [],
            "description": "Epoch 29: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 563,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 563,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_997b73c22e99463ab717438d0901d09f"
          }
        },
        "e6fd8c0c2002436cbf249edfbfd45501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_38cbc2cf830a45fc8f41da2ed9b11f28",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 563/563 [11:49&lt;00:00,  1.26s/it, loss=6, v_num=89fd, val_loss=9.170, average_bleu_score=0.000, train_loss_step=6.100, train_loss_epoch=6.070]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77d4ef615270431b8e5b818851b9b3a3"
          }
        },
        "b7782a6d04a745ba9a2522b08eb8bfca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "997b73c22e99463ab717438d0901d09f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38cbc2cf830a45fc8f41da2ed9b11f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77d4ef615270431b8e5b818851b9b3a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6af0a4f62bd44e2da09713d17a60c4a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2b4e7d4d404a4fb29b4eb15e46498bf2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e9c44ec8eb1b423eb3d6a7ad0baa5da9",
              "IPY_MODEL_b35e44d477c744309d3549b88539d663"
            ]
          }
        },
        "2b4e7d4d404a4fb29b4eb15e46498bf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "e9c44ec8eb1b423eb3d6a7ad0baa5da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f34a54c2a5c44d16b6bcd93b564c593f",
            "_dom_classes": [],
            "description": "Validating: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 0,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9cb17b4abc24b7489d5aa7c4a4071b8"
          }
        },
        "b35e44d477c744309d3549b88539d663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_40b5f25042ff474d999017b1872ebe84",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/0 [24:16&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c31bc5687d9b4a2caf6bd68805fad2be"
          }
        },
        "f34a54c2a5c44d16b6bcd93b564c593f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9cb17b4abc24b7489d5aa7c4a4071b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40b5f25042ff474d999017b1872ebe84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c31bc5687d9b4a2caf6bd68805fad2be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73070c5fadea4dba9d78afb7ba726776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ae4463263cbd45e08e3aa4347d299de6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_009506918195482ebf07558219d9afec",
              "IPY_MODEL_0493c73ea5b442e58197e61e59947836"
            ]
          }
        },
        "ae4463263cbd45e08e3aa4347d299de6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "009506918195482ebf07558219d9afec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6c652b01bd104160a22eb156ca05679e",
            "_dom_classes": [],
            "description": "Validating: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 0,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ba21c40419e4bfa9462a6577af1d6ca"
          }
        },
        "0493c73ea5b442e58197e61e59947836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_51f4ffd3797547348e12f25c65c7221d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/0 [24:44&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05f1cf6660974640bf14a875bfb2e8ed"
          }
        },
        "6c652b01bd104160a22eb156ca05679e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ba21c40419e4bfa9462a6577af1d6ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51f4ffd3797547348e12f25c65c7221d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05f1cf6660974640bf14a875bfb2e8ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad0fa287d9004e93a0cd0a52cf2823cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7eca50030fe548c6b441ec77c0b42645",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a1cd54ed267c40fdbc01c5ad0204c9fa",
              "IPY_MODEL_ba69a8276c8d40e3be558cdc05c2abd8"
            ]
          }
        },
        "7eca50030fe548c6b441ec77c0b42645": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "a1cd54ed267c40fdbc01c5ad0204c9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_203692acabf1495a95488b39e18d703e",
            "_dom_classes": [],
            "description": "Validating: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 0,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef7e89fa5f954f97ab6f241bc669aa7d"
          }
        },
        "ba69a8276c8d40e3be558cdc05c2abd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f620ccd9997a495d8a2388a845a02ff1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/0 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df65cf7703cd469ebf72c2d785a38371"
          }
        },
        "203692acabf1495a95488b39e18d703e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef7e89fa5f954f97ab6f241bc669aa7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f620ccd9997a495d8a2388a845a02ff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df65cf7703cd469ebf72c2d785a38371": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a01d86dd667476bb09359afdbb8a8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6973e382c56f48d3bfb1431bc58acf0d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d5ededb0b6714ee282f2278359ca87d2",
              "IPY_MODEL_a910807d73e0470f87db585bf94c0887"
            ]
          }
        },
        "6973e382c56f48d3bfb1431bc58acf0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5ededb0b6714ee282f2278359ca87d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fec37da9e920414ca6c3a3ffec7dacab",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 30,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 30,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e2db264564b4361b6eb30c3ccaf12a7"
          }
        },
        "a910807d73e0470f87db585bf94c0887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_674a4150e7d74c14a188ee5d5251ed72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 30/30 [00:12&lt;00:00,  2.36it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d610ad2f51645cb90e84a49b47bd103"
          }
        },
        "fec37da9e920414ca6c3a3ffec7dacab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e2db264564b4361b6eb30c3ccaf12a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "674a4150e7d74c14a188ee5d5251ed72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d610ad2f51645cb90e84a49b47bd103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50f740a077094951a8036d1720bd629c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_70d83ceaad2c4033953b057afefe029a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9adee940e7784fcfbed5a98c56d6bc1a",
              "IPY_MODEL_b78e4e0a35ec46cab677cdfe123fe65c"
            ]
          }
        },
        "70d83ceaad2c4033953b057afefe029a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9adee940e7784fcfbed5a98c56d6bc1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8679474ce34941afaea1dec2bed7df73",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ffaff9fffba345d3bf40d1764ea73a87"
          }
        },
        "b78e4e0a35ec46cab677cdfe123fe65c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cf816b5732ef403ab4914d31b3c312bb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9/9 [00:02&lt;00:00,  3.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7d5fe938242429eaece9a853b005b1c"
          }
        },
        "8679474ce34941afaea1dec2bed7df73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ffaff9fffba345d3bf40d1764ea73a87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf816b5732ef403ab4914d31b3c312bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7d5fe938242429eaece9a853b005b1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y75zK1wABo9f"
      },
      "source": [
        "# [CSL 7340] Project\n",
        "\n",
        "## Instructions:\n",
        "1. You can choose any one of the following tasks.\n",
        "2. Evaluation through demo/viva.\n",
        "3. Submission zip file should contain codes (in .py), and report (preferably latex)\n",
        "4. Report must contain links to accessible colab notebooks as well. [with proper output blocks]\n",
        "5. Cite resources appropriately wherever needed.  \n",
        "6. Final evaluation will be on the basis of review, documentation, quality of results generated, discussions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIj6snVgOUta"
      },
      "source": [
        "## Flags for flow controll\n",
        "\n",
        "The `FLAGS` DS is used to store global boolean values that determine the overall behaviour of the project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtOXMTVu6eNN"
      },
      "source": [
        "FLAGS = dict()\n",
        "\n",
        "# If True, this mounts and uses GDrive as persistent storage wherever the notebook supports it.\n",
        "FLAGS['MOUNT_GDRIVE'] = True\n",
        "\n",
        "\n",
        "# Print flag configuration warnings\n",
        "error = lambda msg, **printflags: print(f'\\x1b[1;33;41m ERROR \\x1b[0m: \\x1b[1;35m{msg}\\x1b[0m', **printflags)\n",
        "warn = lambda msg, **printflags: print(f'\\x1b[1;33;41m Warning \\x1b[0m: \\x1b[1;35m{msg}\\x1b[0m', **printflags)\n",
        "info = lambda msg, **printflags: print(f'Info: \\x1b[1;35m{msg}\\x1b[0m', **printflags)\n",
        "log = lambda tag, msg, **printflags: print(f'{tag}: \\x1b[1;35m{msg}\\x1b[0m', **printflags)\n",
        "\n",
        "if not FLAGS['MOUNT_GDRIVE']:\n",
        "  warn('GDrive mounting disabled. The notebook does not have access to persistent storage and hence will not be able to save any data across different sessions.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udmgquGoNY38"
      },
      "source": [
        "## Paths to save/load data\n",
        "\n",
        "The `PATH` DS is used to store file/folder paths for all data/files in the project. This allows easy migration and saving of important files when needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzaz2zMENffk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faa5a817-690f-4d00-d92e-4e4f9dbd147f"
      },
      "source": [
        "import pathlib\n",
        "PATH = dict()\n",
        " \n",
        "PATH['workdir'] = pathlib.Path('./workdir')\n",
        " \n",
        "# Mount GDrive if needed\n",
        "if FLAGS['MOUNT_GDRIVE']:\n",
        "  PATH['gdrive_mount'] = pathlib.Path('./gdrive')           # Used to mount GDrive (do not use for save/load)\n",
        "  PATH['gdrive'] = PATH['gdrive_mount'].joinpath('MyDrive') # Used to save/load files in mounted GDrive\n",
        "  # Mount GDrive\n",
        "  from google.colab import drive\n",
        "  drive.mount(str(PATH['gdrive_mount'].resolve()))\n",
        " \n",
        "# Persistent storage\n",
        "if FLAGS['MOUNT_GDRIVE']:\n",
        "  PATH['workdir_save'] = PATH['gdrive'].joinpath('Classroom', 'CSL7340 - Natural Language Processing (Reg.)', 'NLP Project', 'workdir_save')\n",
        "else:\n",
        "  # TODO: use alternative persistent storage if no GDrive\n",
        "  PATH['workdir_save'] = PATH['workdir']\n",
        "log(f'Persistent storage at', f'{PATH[\"workdir_save\"]}')\n",
        " \n",
        "# Make sure all path folders are created\n",
        "for key, path in PATH.items():\n",
        "  path.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Persistent storage at: \u001b[1;35mgdrive/MyDrive/Classroom/CSL7340 - Natural Language Processing (Reg.)/NLP Project/workdir_save\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iVT4GeYdOf-"
      },
      "source": [
        "## Install libraries and dependencies\n",
        "\n",
        "This cell installs the libraries/dependencies required for this notebook.\n",
        "\n",
        "It can also initialize libraries or required code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU4Cvwfxdb1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa810078-1a6a-4836-855d-eb6ba218f797"
      },
      "source": [
        "# Upgrade gensim\n",
        "# !pip install -U gensim --quiet\n",
        "\n",
        "# Update pytables\n",
        "# Bugfix: https://stackoverflow.com/questions/54210073/pd-read-hdf-throws-cannot-set-writable-flag-to-true-of-this-array\n",
        "!pip install -U tables --quiet\n",
        "\n",
        "# Pandas\n",
        "# !pip install pandas===1.2.3 --quiet\n",
        "\n",
        "# Test versions\n",
        "# import pandas, tables\n",
        "# if pandas.__version__ != '1.2.3':\n",
        "#   # Restart runtime\n",
        "#   warn(\"Package update requires runtime reboot. Automatically crashing runtime. Please run this cell again.\", flush=True)\n",
        "#   import os, time\n",
        "#   time.sleep(1)\n",
        "#   os.kill(os.getpid(), 9)\n",
        "\n",
        "# NLTK and contractions\n",
        "# !pip install nltk --quiet\n",
        "# # Init. NLTK\n",
        "# import nltk\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('wordnet')\n",
        "# nltk.download('averaged_perceptron_tagger')\n",
        "# nltk.download('omw')\n",
        "# nltk.download('stopwords')\n",
        "\n",
        "# Contractions\n",
        "# !pip install contractions --quiet\n",
        "\n",
        "# FlashText, used to replace terms in text with minimal overhead\n",
        "# !pip install flashtext --quiet\n",
        "\n",
        "# Sparse: used to store padded arrays in compressed formats and avoid memory overflow errors\n",
        "# !pip install -U sparse --quiet\n",
        "\n",
        "# Pytorch lightning wrapper library to manage pytorch code cleanly\n",
        "!pip install pytorch-lightning==1.2.4 --quiet\n",
        "!pip install torchmetrics\n",
        "\n",
        "# Better dataclass than pyton's standard version\n",
        "# https://github.com/biqqles/dataclassy\n",
        "!pip install dataclassy --quiet\n",
        "from dataclassy import *\n",
        "\n",
        "# Training visualisation\n",
        "!pip install mlflow --quiet\n",
        "\n",
        "# Kaggle dataset\n",
        "# !pip install -q kaggle\n",
        "\n",
        "# modin - out of core pandas\n",
        "# !pip install modin[ray] --quiet\n",
        "# import ray\n",
        "# ray.init(ignore_reinit_error=True)\n",
        "# import os\n",
        "# os.environ['MODIN_ENGINE'] = 'ray'\n",
        "# os.environ['MODIN_OUT_OF_CORE'] = 'true'\n",
        "# !export MODIN_OUT_OF_CORE=true\n",
        "# import modin.pandas as pd\n",
        "\n",
        "# iNLTK\n",
        "!pip install inltk --quiet\n",
        "# Setup all languages\n",
        "import inltk.inltk as inltk\n",
        "for l in ['hi', 'pa', 'gu', 'kn', 'ml', 'or', 'mr', 'bn', 'ta', 'ur', 'ne', 'sa', 'en', 'te']:\n",
        "  try:\n",
        "    inltk.setup(l)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Model. This might take time, depending on your internet connection. Please be patient.\n",
            "We'll only do this for the first time.\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.3.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (20.9)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.8.1+cu101)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (2.4.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tisnOhLpKadx"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntj4CwBCRZMR"
      },
      "source": [
        "### BackedupResource\n",
        "\n",
        "This class is used to backup and restore file/folder resources."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psfge2jYRlac"
      },
      "source": [
        "import pathlib\n",
        "from abc import ABC, abstractmethod\n",
        "class BackedUpResource(ABC):\n",
        "  def __init__(\n",
        "      self,\n",
        "      resource_path: pathlib.Path,\n",
        "      backup_path: pathlib.Path,\n",
        "      download_path: pathlib.Path = None,\n",
        "      logger = {\n",
        "          'error': error,\n",
        "          'info': info,\n",
        "          'warn': warn,\n",
        "      }\n",
        "    ):\n",
        "    # Fix types\n",
        "    resource_path = pathlib.Path(resource_path)\n",
        "    backup_path = pathlib.Path(backup_path)\n",
        "    # If download path not given, use resource path's parent\n",
        "    if download_path == None:\n",
        "      download_path = resource_path.parent\n",
        "    download_path = pathlib.Path(download_path)\n",
        "    # Check ext.\n",
        "    if backup_path.suffixes[-2:] == ['.tar', '.gz']:\n",
        "      self._compress_arg = 'z'\n",
        "    elif backup_path.suffixes[-1:] == ['.tar']:\n",
        "      self._compress_arg = ''\n",
        "    else:\n",
        "      raise Exception(f'Invalid backup path: \\'{backup_path}\\'. Only \\'.tar.gz\\' or \\'.tar\\' backup file formats supported.')\n",
        "    # Save params\n",
        "    self.resource = resource_path\n",
        "    self.backup = backup_path\n",
        "    self.download_path = download_path\n",
        "    self.log = logger\n",
        "  def exists(self):\n",
        "    return self.resource.exists() or self.backup.exists()\n",
        "  @abstractmethod\n",
        "  def generate(self, resource: pathlib.Path):\n",
        "    '''\n",
        "    Implement this to generate the resource.\n",
        "    '''\n",
        "    pass\n",
        "  def _download(self, target, destination: pathlib.Path):\n",
        "    # create destination dirs\n",
        "    destination.parent.mkdir(parents=True, exist_ok=True)\n",
        "    !rsync -ah --progress '{target.resolve()}' '{destination.resolve()}'\n",
        "  def _upload(self, target, destination: pathlib.Path):\n",
        "    # create destination dirs\n",
        "    destination.parent.mkdir(parents=True, exist_ok=True)\n",
        "    !rsync -ah --progress '{target.resolve()}' '{destination.resolve()}'\n",
        "  def load(self, regenerate=False):\n",
        "    '''\n",
        "    Loads the resource from backup or generates it if it doesn't exist.\n",
        "    Returns the path to the loaded resource.\n",
        "    Implement the self.generate method.\n",
        "\n",
        "    If regenerate is True, this will regenrate the resource and overwrite all backups with the new resource.\n",
        "    '''\n",
        "    # Declare tarfile path\n",
        "    tarfile = self.resource.with_name(self.backup.name)\n",
        "    def _backup():\n",
        "      # compress resource\n",
        "      self.log['info'](f'Adding resource \\'{self.resource.name}\\' to archive.')\n",
        "      comp_arg = self._compress_arg\n",
        "      arg_2 = tarfile.resolve()\n",
        "      file_arg = '.' if self.resource.is_dir() else self.resource.name\n",
        "      arg_3 = self.resource.resolve() if self.resource.is_dir() else self.resource.parent.resolve()\n",
        "      !tar cvf{comp_arg} '{arg_2}' -C '{arg_3}' '{file_arg}'\n",
        "      # upload\n",
        "      if regenerate:\n",
        "        self.log['info']('Overwriting archive to backup.')\n",
        "        !rm -rf '{self.backup.resolve()}'\n",
        "      else:\n",
        "        self.log['info']('Uploading archive to backup.')\n",
        "      self._upload(tarfile, self.backup)\n",
        "      self.log['info'](f'Resource \\'{self.resource.name}\\' backed up at: \\'{self.backup}\\'')\n",
        "    if self.resource.exists() and not regenerate:\n",
        "      # Resource already exists.\n",
        "      if not self.backup.exists():\n",
        "        # Backup resource\n",
        "        self.log['info'](f'Backing up resource \\'{self.resource.name}\\' to: \\'{self.backup}\\'')\n",
        "        _backup()\n",
        "    elif self.backup.exists() and not regenerate:\n",
        "      # Load from backup\n",
        "      self.log['info'](f'Loading resource \\'{self.resource.name}\\' from backup at: \\'{self.backup}\\'')\n",
        "      self.resource.parent.mkdir(parents=True, exist_ok=True)\n",
        "      self.log['info'](f'Downloading backup file to: \\'{tarfile}\\'')\n",
        "      self._download(self.backup, tarfile)\n",
        "      self.log['info'](f'Extracting backup file to: \\'{self.resource}\\'')\n",
        "      # Extract backup\n",
        "      arg_1 = tarfile.resolve()\n",
        "      # count files in tar\n",
        "      file_count = !tar tzf {arg_1} | wc -l\n",
        "      file_count = int(file_count[0])\n",
        "      if file_count > 1:\n",
        "        # make dir\n",
        "        self.resource.mkdir(parents=True, exist_ok=True)\n",
        "      comp_arg = self._compress_arg\n",
        "      dir_arg = self.resource.resolve() if self.resource.is_dir() else self.resource.parent.resolve()\n",
        "      !tar xvf{comp_arg} {arg_1} -C {dir_arg}\n",
        "    else:\n",
        "      if regenerate:\n",
        "        self.log['info'](f'Re-Generating resource \\'{self.resource.name}\\'.')\n",
        "        !rm -rf '{self.resource.resolve()}'\n",
        "        !rm -rf '{tarfile.resolve()}'\n",
        "      else:\n",
        "        # Nothing exists, generate resource\n",
        "        self.log['info'](f'Generating resource \\'{self.resource.name}\\'.')\n",
        "      self.generate(self.resource)\n",
        "      if not self.resource.exists():\n",
        "        raise Exception(f'Cannot backup, resource \\'{self.resource.name}\\' was not generated.')\n",
        "      _backup()\n",
        "    return self.resource\n",
        "\n",
        "\n",
        "class NoGenerateResource(BackedUpResource):\n",
        "  def generate(self, _):\n",
        "    raise Exception('NoGenerateResource cannot be generated. Please make sure the file resource or its backup exists.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYE8gt5PQTCQ"
      },
      "source": [
        "## Q1. \n",
        "Machine Translation: (that translates sentences from one language to another)\n",
        "\n",
        "1. Data:- Choose any corpus from https://indicnlp.ai4bharat.org/samanantar/ \n",
        "2. Detailed review of at least three papers presented in NIPS / ACL / KDD / COLING / NAACL / conference of similar tier over the last 3 years - that addresses the task using a DL architecture.\n",
        "3. Implement a DL model for solving the task. Your implementation may be one of the architectures reviewed in step b, or a mixture, or a completely novel one.\n",
        "4. Discuss the evaluation metrics used to judge the performance of the model, show the model performance using these metrics. Comment on the model's performance. Compare your results with the papers reviewed.\n",
        "5. Make a clear documentation of the same along with model related information like architecture, training, validation and test splits, hyperparameters choice (and appropriate reasoning), and any other design considerations made, shortcomings of the model, limitations etc.\n",
        "6. Show some examples where the model has given correct translations as well as some wrong ones.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TITdpebXQNhE"
      },
      "source": [
        "### Download and setup data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vHIkQgDP5Zw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebcf0424-379e-4729-c487-85c9cd7414a8"
      },
      "source": [
        "import pandas as pd\n",
        "class DatasetLoader(BackedUpResource):\n",
        "  def __init__(\n",
        "      self,\n",
        "      dataset_file: pathlib.Path,\n",
        "      backup_path: pathlib.Path,\n",
        "      download_path: pathlib.Path = None,\n",
        "      dataset_key = 'en-hi',\n",
        "    ):\n",
        "    super().__init__(dataset_file, backup_path, download_path)\n",
        "    self.dataset_key = dataset_key\n",
        "  def generate(self, dataset_file):\n",
        "    # download zip file\n",
        "    self.download_path.mkdir(exist_ok=True, parents=True)\n",
        "    downfolder = self.download_path.resolve()\n",
        "    dataset_url = \"https://akpublicdata.blob.core.windows.net/indicnlp/samanatar/v0.2/samanatar-en-indic-v0.2.zip\"\n",
        "    self.log['info']('Downloading dataset zip file...')\n",
        "    !cd '{downfolder}' && curl -L -z dataset.zip --create-dirs '{dataset_url}' -o dataset.zip.temp && mv -f dataset.zip.temp dataset.zip 2>/dev/null || rm -f dataset.zip.temp\n",
        "    # create dataset folder\n",
        "    downfile = downfolder.joinpath('dataset.zip')\n",
        "    if not downfile.exists():\n",
        "      raise Exception(f'Could not download dataset file from: {dataset_url}')\n",
        "    dataset_file.mkdir(exist_ok=True, parents=True)\n",
        "    self.log['info']('Extracting data...')\n",
        "    temp = f'final_data/{self.dataset_key}/*'\n",
        "    !cd '{downfolder}' && unzip '{downfile.resolve()}' '{temp}'\n",
        "    temp = downfolder / 'final_data' / self.dataset_key\n",
        "    # Move files to resource folder\n",
        "    !mv '{temp}'/* '{dataset_file}'/\n",
        "    self.log['info'](f'Done.')\n",
        "  def load_memory(\n",
        "      self,\n",
        "      max_entries=25_000,\n",
        "      regenerate=False\n",
        "      ):\n",
        "    folder = self.load(regenerate=regenerate)\n",
        "    a,b = self.dataset_key.split('-')\n",
        "    df = dict()\n",
        "    for l in (a,b,):\n",
        "      with open(folder / f'train.{l}') as f:\n",
        "        df[l] = [next(f).strip() for x in range(max_entries)]\n",
        "    return pd.DataFrame(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Model. This might take time, depending on your internet connection. Please be patient.\n",
            "We'll only do this for the first time.\n",
            "Downloading Model. This might take time, depending on your internet connection. Please be patient.\n",
            "We'll only do this for the first time.\n",
            "Downloading Model. This might take time, depending on your internet connection. Please be patient.\n",
            "We'll only do this for the first time.\n",
            "Downloading Model. This might take time, depending on your internet connection. Please be patient.\n",
            "We'll only do this for the first time.\n",
            "Downloading Model. This might take time, depending on your internet connection. Please be patient.\n",
            "We'll only do this for the first time.\n",
            "Downloading Model. This might take time, depending on your internet connection. Please be patient.\n",
            "We'll only do this for the first time.\n",
            "Downloading Model. This might take time, depending on your internet connection. Please be patient.\n",
            "We'll only do this for the first time.\n",
            "Downloading Model. This might take time, depending on your internet connection. Please be patient.\n",
            "We'll only do this for the first time.\n",
            "Downloading Model. This might take time, depending on your internet connection. Please be patient.\n",
            "We'll only do this for the first time.\n",
            "Downloading Model. This might take time, depending on your internet connection. Please be patient.\n",
            "We'll only do this for the first time.\n",
            "Downloading Model. This might take time, depending on your internet connection. Please be patient.\n",
            "We'll only do this for the first time.\n",
            "Downloading Model. This might take time, depending on your internet connection. Please be patient.\n",
            "We'll only do this for the first time.\n",
            "Downloading Model. This might take time, depending on your internet connection. Please be patient.\n",
            "We'll only do this for the first time.\n",
            "Downloading Model. This might take time, depending on your internet connection. Please be patient.\n",
            "We'll only do this for the first time.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "ol-XgCyETEAM",
        "outputId": "af2de075-b4d2-445e-cc45-11ce232814e5"
      },
      "source": [
        "# Setup paths\n",
        "PATH['Q1'] = PATH['workdir'] / 'Q1'\n",
        "PATH['Q1_save'] = PATH['workdir_save'] / 'Q1'\n",
        "\n",
        "PATH['Q1'].mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Select language pair\n",
        "LANG_SRC = 'en'\n",
        "LANG_TARGET = 'hi'\n",
        "DATASET_KEY = f'{LANG_SRC}-{LANG_TARGET}'\n",
        "\n",
        "dataset_loader = DatasetLoader(\n",
        "    PATH['Q1'] / f'dataset_{DATASET_KEY}',\n",
        "    PATH['Q1_save'] / f'dataset_{DATASET_KEY}.tar.gz',\n",
        "    dataset_key = DATASET_KEY,\n",
        ")\n",
        "\n",
        "# Load data\n",
        "if not('DATA' in locals()):\n",
        "  DATA = dataset_loader.load_memory()\n",
        "DATA"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Info: \u001b[1;35mLoading resource 'dataset_en-hi' from backup at: 'gdrive/MyDrive/Classroom/CSL7340 - Natural Language Processing (Reg.)/NLP Project/workdir_save/Q1/dataset_en-hi.tar.gz'\u001b[0m\n",
            "Info: \u001b[1;35mDownloading backup file to: 'workdir/Q1/dataset_en-hi.tar.gz'\u001b[0m\n",
            "sending incremental file list\n",
            "dataset_en-hi.tar.gz\n",
            "        849.71M 100%   58.97MB/s    0:00:13 (xfr#1, to-chk=0/1)\n",
            "Info: \u001b[1;35mExtracting backup file to: 'workdir/Q1/dataset_en-hi'\u001b[0m\n",
            "./\n",
            "./train.en\n",
            "./train.hi\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>hi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In reply, Pakistan got off to a solid start.</td>\n",
              "      <td>जिसके जवाब में पाक ने अच्छी शुरुआत की थी.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The European Union has seven principal decisio...</td>\n",
              "      <td>यूरोपीय संघ के महत्वपूर्ण संस्थानों में यूरोपि...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Congress leader represents Sivaganga Lok S...</td>\n",
              "      <td>कांग्रेस नेता तमिलनाडु से शिवगंगा लोकसभा क्षेत...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Prompt the user about connection attempts</td>\n",
              "      <td>संबंधन प्रयास के बारे में उपयोक्ता को प्रांप्ट...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Further, the Minister announced that Deposit I...</td>\n",
              "      <td>वित्त मंत्री ने घोषणा कि जमा बीमा और ऋण गारंटी...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>All of you, stay back!</td>\n",
              "      <td>ओरेकल!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>Yes, even though we are imperfect and make mis...</td>\n",
              "      <td>माना कि हम असिद्ध हैं और गलतियाँ करते हैं, फिर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>It's not the President.</td>\n",
              "      <td>यह राष्ट्रपति नहीं है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>When so...</td>\n",
              "      <td>इस बारे में जब .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>That verse does not specifically refer to the ...</td>\n",
              "      <td>उस आयत में बाइबल की नहीं बल्कि बाइबल में दिए स...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      en                                                 hi\n",
              "0           In reply, Pakistan got off to a solid start.          जिसके जवाब में पाक ने अच्छी शुरुआत की थी.\n",
              "1      The European Union has seven principal decisio...  यूरोपीय संघ के महत्वपूर्ण संस्थानों में यूरोपि...\n",
              "2      The Congress leader represents Sivaganga Lok S...  कांग्रेस नेता तमिलनाडु से शिवगंगा लोकसभा क्षेत...\n",
              "3              Prompt the user about connection attempts  संबंधन प्रयास के बारे में उपयोक्ता को प्रांप्ट...\n",
              "4      Further, the Minister announced that Deposit I...  वित्त मंत्री ने घोषणा कि जमा बीमा और ऋण गारंटी...\n",
              "...                                                  ...                                                ...\n",
              "24995                             All of you, stay back!                                             ओरेकल!\n",
              "24996  Yes, even though we are imperfect and make mis...  माना कि हम असिद्ध हैं और गलतियाँ करते हैं, फिर...\n",
              "24997                            It's not the President.                             यह राष्ट्रपति नहीं है।\n",
              "24998                                         When so...                                   इस बारे में जब .\n",
              "24999  That verse does not specifically refer to the ...  उस आयत में बाइबल की नहीं बल्कि बाइबल में दिए स...\n",
              "\n",
              "[25000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Nz5ArpKhFOZ"
      },
      "source": [
        "### Tokenize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4swRhIWrENB"
      },
      "source": [
        "class SeriesApplyDataLoader(BackedUpResource):\n",
        "  def __init__(\n",
        "      self,\n",
        "      df_col,\n",
        "      apply_func,\n",
        "      dataset_file: pathlib.Path,\n",
        "      backup_path: pathlib.Path,\n",
        "      download_path: pathlib.Path = None,\n",
        "    ):\n",
        "    assert dataset_file.name[-5:]=='.hdf5'\n",
        "    super().__init__(dataset_file, backup_path, download_path)\n",
        "    self.apply_func = apply_func\n",
        "    self.df = df_col\n",
        "  def generate(self, dataset_file):\n",
        "    self.log['info']('Applying function to df...')\n",
        "    tqdm.pandas()\n",
        "    df = self.df.progress_apply(self.apply_func).astype('object')\n",
        "    # Save df\n",
        "    self.log['info']('Saving result to hdf5...')\n",
        "    df.to_hdf(dataset_file, key='df')\n",
        "  def load_memory(self, regenerate=False):\n",
        "    f = self.load(regenerate=regenerate)\n",
        "    return pd.read_hdf(f, key='df')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "LAG5xTXfp3HA",
        "outputId": "b05cf5dc-ae22-420e-acd1-2c2d5d22151f"
      },
      "source": [
        "# get Tokenize function\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "# Make tokenized data\n",
        "src_tok_loader = SeriesApplyDataLoader(\n",
        "    df_col=DATA[LANG_SRC],\n",
        "    apply_func=en_tokenizer if LANG_SRC=='en' else lambda e: inltk.tokenize(e, LANG_SRC),\n",
        "    dataset_file=PATH['Q1'] / f'{LANG_SRC}_tok.hdf5',\n",
        "    backup_path=PATH['Q1_save'] / f'{LANG_SRC}_tok.tar.gz'\n",
        ")\n",
        "target_tok_loader = SeriesApplyDataLoader(\n",
        "    df_col=DATA[LANG_TARGET],\n",
        "    apply_func=en_tokenizer if LANG_TARGET=='en' else lambda e: inltk.tokenize(e, LANG_TARGET),\n",
        "    dataset_file=PATH['Q1'] / f'{LANG_TARGET}_tok.hdf5',\n",
        "    backup_path=PATH['Q1_save'] / f'{LANG_TARGET}_tok.tar.gz'\n",
        ")\n",
        "\n",
        "# Load tokenized data\n",
        "DATA['en_tok'] = src_tok_loader.load_memory()\n",
        "DATA['hi_tok'] = target_tok_loader.load_memory()\n",
        "\n",
        "# Show data\n",
        "DATA"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Info: \u001b[1;35mLoading resource 'en_tok.hdf5' from backup at: 'gdrive/MyDrive/Classroom/CSL7340 - Natural Language Processing (Reg.)/NLP Project/workdir_save/Q1/en_tok.tar.gz'\u001b[0m\n",
            "Info: \u001b[1;35mDownloading backup file to: 'workdir/Q1/en_tok.tar.gz'\u001b[0m\n",
            "sending incremental file list\n",
            "en_tok.tar.gz\n",
            "          1.31M 100%  135.45MB/s    0:00:00 (xfr#1, to-chk=0/1)\n",
            "Info: \u001b[1;35mExtracting backup file to: 'workdir/Q1/en_tok.hdf5'\u001b[0m\n",
            "en_tok.hdf5\n",
            "Info: \u001b[1;35mLoading resource 'hi_tok.hdf5' from backup at: 'gdrive/MyDrive/Classroom/CSL7340 - Natural Language Processing (Reg.)/NLP Project/workdir_save/Q1/hi_tok.tar.gz'\u001b[0m\n",
            "Info: \u001b[1;35mDownloading backup file to: 'workdir/Q1/hi_tok.tar.gz'\u001b[0m\n",
            "sending incremental file list\n",
            "hi_tok.tar.gz\n",
            "          1.91M 100%    4.79MB/s    0:00:00 (xfr#1, to-chk=0/1)\n",
            "Info: \u001b[1;35mExtracting backup file to: 'workdir/Q1/hi_tok.hdf5'\u001b[0m\n",
            "hi_tok.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>hi</th>\n",
              "      <th>en_tok</th>\n",
              "      <th>hi_tok</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In reply, Pakistan got off to a solid start.</td>\n",
              "      <td>जिसके जवाब में पाक ने अच्छी शुरुआत की थी.</td>\n",
              "      <td>[In, reply, ,, Pakistan, got, off, to, a, soli...</td>\n",
              "      <td>[▁जिसके, ▁जवाब, ▁में, ▁पाक, ▁ने, ▁अच्छी, ▁शुरु...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The European Union has seven principal decisio...</td>\n",
              "      <td>यूरोपीय संघ के महत्वपूर्ण संस्थानों में यूरोपि...</td>\n",
              "      <td>[The, European, Union, has, seven, principal, ...</td>\n",
              "      <td>[▁यूरोपीय, ▁संघ, ▁के, ▁महत्वपूर्ण, ▁संस्थानों,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Congress leader represents Sivaganga Lok S...</td>\n",
              "      <td>कांग्रेस नेता तमिलनाडु से शिवगंगा लोकसभा क्षेत...</td>\n",
              "      <td>[The, Congress, leader, represents, Sivaganga,...</td>\n",
              "      <td>[▁कांग्रेस, ▁नेता, ▁तमिलनाडु, ▁से, ▁शिव, गंगा,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Prompt the user about connection attempts</td>\n",
              "      <td>संबंधन प्रयास के बारे में उपयोक्ता को प्रांप्ट...</td>\n",
              "      <td>[Prompt, the, user, about, connection, attempts]</td>\n",
              "      <td>[▁संबंध, न, ▁प्रयास, ▁के, ▁बारे, ▁में, ▁उपयोक्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Further, the Minister announced that Deposit I...</td>\n",
              "      <td>वित्त मंत्री ने घोषणा कि जमा बीमा और ऋण गारंटी...</td>\n",
              "      <td>[Further, ,, the, Minister, announced, that, D...</td>\n",
              "      <td>[▁वित्त, ▁मंत्री, ▁ने, ▁घोषणा, ▁कि, ▁जमा, ▁बीम...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>All of you, stay back!</td>\n",
              "      <td>ओरेकल!</td>\n",
              "      <td>[All, of, you, ,, stay, back, !]</td>\n",
              "      <td>[▁ओरेकल, !]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>Yes, even though we are imperfect and make mis...</td>\n",
              "      <td>माना कि हम असिद्ध हैं और गलतियाँ करते हैं, फिर...</td>\n",
              "      <td>[Yes, ,, even, though, we, are, imperfect, and...</td>\n",
              "      <td>[▁माना, ▁कि, ▁हम, ▁अ, सिद्ध, ▁हैं, ▁और, ▁गलत, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>It's not the President.</td>\n",
              "      <td>यह राष्ट्रपति नहीं है।</td>\n",
              "      <td>[It, 's, not, the, President, .]</td>\n",
              "      <td>[▁यह, ▁राष्ट्रपति, ▁नहीं, ▁है, ।]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>When so...</td>\n",
              "      <td>इस बारे में जब .</td>\n",
              "      <td>[When, so, ...]</td>\n",
              "      <td>[▁इस, ▁बारे, ▁में, ▁जब, ▁.]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>That verse does not specifically refer to the ...</td>\n",
              "      <td>उस आयत में बाइबल की नहीं बल्कि बाइबल में दिए स...</td>\n",
              "      <td>[That, verse, does, not, specifically, refer, ...</td>\n",
              "      <td>[▁उस, ▁आयत, ▁में, ▁बाइबल, ▁की, ▁नहीं, ▁बल्कि, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      en  ...                                             hi_tok\n",
              "0           In reply, Pakistan got off to a solid start.  ...  [▁जिसके, ▁जवाब, ▁में, ▁पाक, ▁ने, ▁अच्छी, ▁शुरु...\n",
              "1      The European Union has seven principal decisio...  ...  [▁यूरोपीय, ▁संघ, ▁के, ▁महत्वपूर्ण, ▁संस्थानों,...\n",
              "2      The Congress leader represents Sivaganga Lok S...  ...  [▁कांग्रेस, ▁नेता, ▁तमिलनाडु, ▁से, ▁शिव, गंगा,...\n",
              "3              Prompt the user about connection attempts  ...  [▁संबंध, न, ▁प्रयास, ▁के, ▁बारे, ▁में, ▁उपयोक्...\n",
              "4      Further, the Minister announced that Deposit I...  ...  [▁वित्त, ▁मंत्री, ▁ने, ▁घोषणा, ▁कि, ▁जमा, ▁बीम...\n",
              "...                                                  ...  ...                                                ...\n",
              "24995                             All of you, stay back!  ...                                        [▁ओरेकल, !]\n",
              "24996  Yes, even though we are imperfect and make mis...  ...  [▁माना, ▁कि, ▁हम, ▁अ, सिद्ध, ▁हैं, ▁और, ▁गलत, ...\n",
              "24997                            It's not the President.  ...                  [▁यह, ▁राष्ट्रपति, ▁नहीं, ▁है, ।]\n",
              "24998                                         When so...  ...                        [▁इस, ▁बारे, ▁में, ▁जब, ▁.]\n",
              "24999  That verse does not specifically refer to the ...  ...  [▁उस, ▁आयत, ▁में, ▁बाइबल, ▁की, ▁नहीं, ▁बल्कि, ...\n",
              "\n",
              "[25000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OATgu932Slkc"
      },
      "source": [
        "### Build vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366,
          "referenced_widgets": [
            "e5fa630826a54e9894b646ba91960dca",
            "49541d56953541009d8dd2c47b631560",
            "f2804126f7274540b1bfb2aff4a5fe83",
            "cf5aee74e58348bc868d93d487fd83f9",
            "5ac526f101de4762a76494d7931a7396",
            "46d1f6c27f574ac1a7dc58c0edc4f675",
            "4d0807fd29d34c868f7b3735ea81da38",
            "9ea3fbf61d4544fb93cb21e3500a63ec",
            "af32980118134ddf86fbf29275bacf3c",
            "9d80148b52d14b3297fb37a67fa570b5",
            "aa86829ad18840108cd71c23c96baa6b",
            "71456887dc6e4af68bd6739840b583bd",
            "04dbc947e8424b2abc4edd12844d71a1",
            "b79d3245d3ae4bc0a12bb095ae8dd341",
            "74b2f982ad03479ebab52f0ef6757bfd",
            "3e4d399de01843ccb44da57eeb0d63ed"
          ]
        },
        "id": "2R5XTXgCSmjp",
        "outputId": "c4206d86-a0d6-458c-f23f-3650a84c818f"
      },
      "source": [
        "# Reference: https://pytorch.org/tutorials/beginner/translation_transformer.html\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "\n",
        "en_Counter = Counter()\n",
        "en_max_seq_length = 0\n",
        "for v in tqdm(DATA['en_tok']):\n",
        "  en_Counter.update(v)\n",
        "  en_max_seq_length = max(en_max_seq_length, len(v))\n",
        "\n",
        "hi_Counter = Counter()\n",
        "hi_max_seq_length = 0\n",
        "for v in tqdm(DATA['hi_tok']):\n",
        "  hi_Counter.update(v)\n",
        "  hi_max_seq_length = max(hi_max_seq_length, len(v))\n",
        "\n",
        "# Make Vocabs\n",
        "EN_VOCAB = Vocab(en_Counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
        "HI_VOCAB = Vocab(hi_Counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
        "\n",
        "PAD_IDX = EN_VOCAB['<pad>']\n",
        "BOS_IDX = EN_VOCAB['<bos>']\n",
        "EOS_IDX = EN_VOCAB['<eos>']\n",
        "\n",
        "# Show data\n",
        "log('EN_VOCAB size', len(EN_VOCAB))\n",
        "log('EN max seq. length', en_max_seq_length)\n",
        "log('HI_VOCAB size', len(HI_VOCAB))\n",
        "log('HI max seq. length', hi_max_seq_length)\n",
        "\n",
        "# Show sample data\n",
        "info('Sample stoi data:-')\n",
        "list(HI_VOCAB.stoi.items())[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5fa630826a54e9894b646ba91960dca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af32980118134ddf86fbf29275bacf3c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "EN_VOCAB size: \u001b[1;35m35970\u001b[0m\n",
            "EN max seq. length: \u001b[1;35m227\u001b[0m\n",
            "HI_VOCAB size: \u001b[1;35m20782\u001b[0m\n",
            "HI max seq. length: \u001b[1;35m333\u001b[0m\n",
            "Info: \u001b[1;35mSample stoi data:-\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<unk>', 0),\n",
              " ('<pad>', 1),\n",
              " ('<bos>', 2),\n",
              " ('<eos>', 3),\n",
              " ('▁के', 4),\n",
              " ('।', 5),\n",
              " ('▁में', 6),\n",
              " ('▁है', 7),\n",
              " (',', 8),\n",
              " ('▁की', 9)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t5WHCXTQfT0"
      },
      "source": [
        "### Build dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHpxhVF2QhFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1044fcef-4460-46ff-dea8-c3c38ee99ffc"
      },
      "source": [
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Any\n",
        "class BatchingDataModule(pl.LightningDataModule):\n",
        "  @dataclass(frozen=True)\n",
        "  class Parameters:\n",
        "    @dataclass\n",
        "    class LangParams:\n",
        "      data: Any\n",
        "      vocab: Vocab\n",
        "      pad_idx: int\n",
        "      bos_idx:int\n",
        "      eos_idx: int\n",
        "    src: 'BatchingDataModule.Paramaters.LangParams'\n",
        "    target: 'BatchingDataModule.Paramaters.LangParams'\n",
        "    test_size_ratio: float = 0.2\n",
        "    val_size_ratio: float = 0.1\n",
        "    batch_size: int\n",
        "  def __init__(self, params: 'EmbeddingDataModule.Parameters'):\n",
        "    super().__init__()\n",
        "    self.params = params\n",
        "  def prepare_data(self):\n",
        "    X = self.params.src.data\n",
        "    Y = self.params.target.data\n",
        "    # Split train test data\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=self.params.test_size_ratio)\n",
        "    # Split train val data\n",
        "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=self.params.val_size_ratio)\n",
        "    # save data\n",
        "    self.train = (X_train, Y_train)\n",
        "    self.test = (X_test, Y_test)\n",
        "    self.val = (X_val, Y_val)\n",
        "  def collate_fn(self, batch):\n",
        "    def sentence_to_tensor(s, lang):\n",
        "      return torch.tensor(\n",
        "          [lang.bos_idx] + [lang.vocab[tk] for tk in s] + [lang.eos_idx],\n",
        "          dtype=torch.long\n",
        "        )\n",
        "    x, y = [i[0] for i in batch], [i[1] for i in batch]\n",
        "    x = pad_sequence([sentence_to_tensor(i, self.params.src) for i in x], padding_value=self.params.src.pad_idx)\n",
        "    y = pad_sequence([sentence_to_tensor(i, self.params.target) for i in y], padding_value=self.params.target.pad_idx)\n",
        "    return x, y\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(list(zip(*self.train)), batch_size=self.params.batch_size, collate_fn=self.collate_fn)\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(list(zip(*self.val)), batch_size=self.params.batch_size, collate_fn=self.collate_fn)\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(list(zip(*self.test)), batch_size=self.params.batch_size, collate_fn=self.collate_fn)\n",
        "\n",
        "# Sample Datamodule\n",
        "sample_datamodule = BatchingDataModule(\n",
        "    BatchingDataModule.Parameters(\n",
        "        src=BatchingDataModule.Parameters.LangParams(\n",
        "            data=DATA['en_tok'],\n",
        "            vocab=EN_VOCAB,\n",
        "            pad_idx=PAD_IDX,\n",
        "            bos_idx=BOS_IDX,\n",
        "            eos_idx=EOS_IDX,\n",
        "        ),\n",
        "        target=BatchingDataModule.Parameters.LangParams(\n",
        "            data=DATA['hi_tok'],\n",
        "            vocab=HI_VOCAB,\n",
        "            pad_idx=PAD_IDX,\n",
        "            bos_idx=BOS_IDX,\n",
        "            eos_idx=EOS_IDX,\n",
        "        ),\n",
        "        batch_size=1,\n",
        "    )\n",
        ")\n",
        "sample_datamodule.prepare_data()\n",
        "sample_batch = next(iter(sample_datamodule.train_dataloader()))\n",
        "log('Sample batch size', 1)\n",
        "log('Sample batch src shape:', sample_batch[0].shape)\n",
        "log('Sample batch target shape:', sample_batch[1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample batch size: \u001b[1;35m1\u001b[0m\n",
            "Sample batch src shape:: \u001b[1;35mtorch.Size([54, 1])\u001b[0m\n",
            "Sample batch target shape:: \u001b[1;35mtorch.Size([114, 1])\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WEWJuJ8hDvn"
      },
      "source": [
        "### Token embedding and positional encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPsuHwqBhHDz"
      },
      "source": [
        "import math\n",
        "class Positional_Embedding(pl.LightningModule):\n",
        "  @dataclass(frozen=True)\n",
        "  class Parameters:\n",
        "    embedding_dim: int\n",
        "    max_seq_length: int\n",
        "    dropout: float = 0.1\n",
        "  def __init__(self, params: 'Positional_Embedding.Parameters'):\n",
        "    super().__init__()\n",
        "    self.params = params\n",
        "    # Pre-compute positional embeddings\n",
        "    den = torch.exp( -torch.arange(0, params.embedding_dim, 2, device=self.device) * math.log(10000) / params.embedding_dim)\n",
        "    pos = torch.arange(0, params.max_seq_length, device=self.device).reshape(params.max_seq_length, 1)\n",
        "    pos_embedding = torch.zeros((params.max_seq_length, params.embedding_dim), device=self.device)\n",
        "    pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "    pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "    pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "    # Store pre-computed data and dropout layer\n",
        "    self.dropout = torch.nn.Dropout(params.dropout)\n",
        "    self.register_buffer('pos_embedding', pos_embedding)\n",
        "  def forward(self, token_embedding: torch.Tensor):\n",
        "    return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0),:])\n",
        "\n",
        "class Token_Embedding(pl.LightningModule):\n",
        "  @dataclass(frozen=True)\n",
        "  class Parameters:\n",
        "    embedding_dim: int\n",
        "    vocab_size: int\n",
        "  def __init__(self, params: 'Positional_Embedding.Parameters'):\n",
        "    super().__init__()\n",
        "    self.params = params\n",
        "    self.emb = torch.nn.Embedding(params.vocab_size, params.embedding_dim)\n",
        "  def forward(self, tokens: torch.Tensor):\n",
        "    return self.emb(tokens.long()) * math.sqrt(self.params.embedding_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP6QFuNKeRIi"
      },
      "source": [
        "### Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoTXAkmweSvz",
        "outputId": "f75d510d-33f2-464c-e67f-dca7ab1f208f"
      },
      "source": [
        "import pytorch_lightning as pl\n",
        "from torchtext.vocab import Vocab\n",
        "from torchmetrics.functional import bleu_score\n",
        "import torch\n",
        "\n",
        "class Transformer_Model(pl.LightningModule):\n",
        "  @dataclass(frozen=True)\n",
        "  class Parameters:\n",
        "    @dataclass\n",
        "    class LangParams:\n",
        "      vocab: Vocab\n",
        "      max_seq_length: int\n",
        "      pad_idx: int\n",
        "      bos_idx:int\n",
        "      eos_idx: int\n",
        "    src: 'Transformer_Model.Paramaters.LangParams'\n",
        "    target: 'Transformer_Model.Paramaters.LangParams'\n",
        "    encoder_layers: int\n",
        "    decoder_layers: int\n",
        "    embedding_dim: int\n",
        "    learning_rate: float = 0.0001\n",
        "    attention_heads: int = 8\n",
        "    linear_dim: int = 512\n",
        "    dropout: float = 0.1\n",
        "  def __init__(self, params: 'Transformer_Model.Parameters'):\n",
        "    super().__init__()\n",
        "    self.params = params\n",
        "    # Encoder layer\n",
        "    enc_layer = torch.nn.TransformerEncoderLayer(\n",
        "        d_model=params.embedding_dim,\n",
        "        nhead=params.attention_heads,\n",
        "        dim_feedforward=params.linear_dim,\n",
        "        dropout=params.dropout,\n",
        "    )\n",
        "    # Encoder\n",
        "    self.enc = torch.nn.TransformerEncoder(\n",
        "        enc_layer, num_layers=params.encoder_layers\n",
        "    )\n",
        "    # Decoder layer\n",
        "    dec_layer = torch.nn.TransformerDecoderLayer(\n",
        "        d_model=params.embedding_dim,\n",
        "        nhead=params.attention_heads,\n",
        "        dim_feedforward=params.linear_dim,\n",
        "        dropout=params.dropout,\n",
        "    )\n",
        "    # Decoder\n",
        "    self.dec = torch.nn.TransformerDecoder(\n",
        "        dec_layer, num_layers=params.encoder_layers\n",
        "    )\n",
        "    # Generator\n",
        "    self.gen = torch.nn.Linear(params.embedding_dim, len(params.target.vocab))\n",
        "    # Token Embedding layers\n",
        "    self.src_emb = Token_Embedding(Token_Embedding.Parameters(\n",
        "        embedding_dim=params.embedding_dim,\n",
        "        vocab_size=len(params.src.vocab)\n",
        "    ))\n",
        "    self.target_emb = Token_Embedding(Token_Embedding.Parameters(\n",
        "        embedding_dim=params.embedding_dim,\n",
        "        vocab_size=len(params.target.vocab)\n",
        "    ))\n",
        "    # Positional Embedding layer\n",
        "    self.pos_emb = Positional_Embedding(Positional_Embedding.Parameters(\n",
        "        embedding_dim=params.embedding_dim,\n",
        "        max_seq_length=5000,\n",
        "        dropout=params.dropout,\n",
        "    ))\n",
        "  \n",
        "  def create_masks(self, src, target):\n",
        "    # Padded sequence lengths\n",
        "    src_seq_len = src.shape[0]\n",
        "    target_seq_len = target.shape[0]\n",
        "    # target mask\n",
        "    target_mask = (torch.triu(torch.ones((target_seq_len, target_seq_len), device=self.device)) == 1).transpose(0, 1)\n",
        "    target_mask = target_mask.float().masked_fill(target_mask == 0, float('-inf')).masked_fill(target_mask == 1, float(0.0))\n",
        "    # source mask\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=self.device).bool()\n",
        "    # padding masks\n",
        "    src_padding_mask = (src == self.params.src.pad_idx).transpose(0, 1)\n",
        "    target_padding_mask = (target == self.params.target.pad_idx).transpose(0, 1)\n",
        "    return src_mask, target_mask, src_padding_mask, target_padding_mask\n",
        "  \n",
        "  def forward(self, src, target, src_mask, target_mask, src_padding_mask, target_padding_mask, memory_key_padding_mask):\n",
        "    # token embedding and positional encoding\n",
        "    src_emb = self.pos_emb(self.src_emb(src))\n",
        "    target_emb = self.pos_emb(self.target_emb(target))\n",
        "    # encode\n",
        "    memory = self.enc(src_emb, src_mask, src_padding_mask)\n",
        "    # decode\n",
        "    outs = self.dec(target_emb, memory, target_mask, None, target_padding_mask, memory_key_padding_mask)\n",
        "    # Final linear layer\n",
        "    return self.gen(outs)\n",
        "  \n",
        "  def translate(self, src_sentence, src_tokenizer, max_tokens=500):\n",
        "    '''\n",
        "    Accepts a sentence in source language and returns a target language sentence.\n",
        "    Parameters:-\n",
        "      src_sentence: Input sentence string\n",
        "      src_tokenizer: Callable that is used to tokenize the source sentence.\n",
        "    '''\n",
        "    src_params = self.params.src\n",
        "    tokens = [src_params.bos_idx] + [src_params.vocab.stoi[i] for i in src_tokenizer(src_sentence)] + [src_params.eos_idx]\n",
        "    src = torch.LongTensor(tokens).to(self.device)\n",
        "    ys = self.translate_tokenized(src, max_tokens)\n",
        "    # Convert ys to string and return\n",
        "    return \"\".join([self.params.target.vocab.itos[i] for i in ys]).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").replace(\"▁\", \" \")\n",
        "    \n",
        "  def translate_tokenized(self, src: torch.Tensor, max_tokens=500):\n",
        "    '''\n",
        "    Accepts a tokenized sentence tensor in source language and returns a tokenized sentence in target language.\n",
        "    Note the tokens include <bos> and <eos>.\n",
        "    '''\n",
        "    src_params = self.params.src\n",
        "    src_len = len(src)\n",
        "    src = src.reshape(src_len, 1)\n",
        "    src_mask = torch.zeros(src_len, src_len, device=self.device).bool()\n",
        "    # Encode\n",
        "    memory = self.enc(self.pos_emb(self.src_emb(src)), src_mask)\n",
        "    # The tensor that stores the generated sentence\n",
        "    ys = torch.ones(1, 1, device=self.device).fill_(src_params.bos_idx).long()\n",
        "    # Deocder loop (1 token will be <bos>)\n",
        "    for i in range(max_tokens):\n",
        "      memory_mask = torch.zeros(ys.shape[0], memory.shape[0], device=self.device).bool()\n",
        "      target_mask = (torch.triu(torch.ones((ys.size(0), ys.size(0)), device=self.device)) == 1).transpose(0, 1)\n",
        "      target_mask = target_mask.float().masked_fill(target_mask == 0, float('-inf')).masked_fill(target_mask == 1, float(0.0))\n",
        "      # Decode next token\n",
        "      out = self.dec(self.pos_emb(self.target_emb(ys.float())), memory, target_mask).transpose(0, 1)\n",
        "      prob = self.gen(out[:, -1])\n",
        "      _, next_word = torch.max(prob, dim = 1)\n",
        "      next_word = next_word.item()\n",
        "      # Break if model generated eos\n",
        "      if next_word == EOS_IDX:\n",
        "        break\n",
        "      # Prepare ys for next iteration\n",
        "      ys = torch.cat([ys, torch.ones(1, 1, device=self.device).type_as(src.data).fill_(next_word)], dim=0)\n",
        "    return ys.flatten()\n",
        "  \n",
        "  def training_step(self, batch, batch_idx):\n",
        "    ret = self._step(batch, batch_idx)\n",
        "    # log loss\n",
        "    self.log('train_loss', ret['loss'], on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
        "    return ret\n",
        "  \n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    ret = self._step(batch, batch_idx)\n",
        "    # log loss\n",
        "    self.log('val_loss', ret['loss'], on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
        "    # measure average bleu score for every sentence\n",
        "    bleu_sum = 0\n",
        "    for x,y in zip(*batch):\n",
        "      translated = self.translate_tokenized(x, max_tokens=len(y))\n",
        "      target = [self.params.target.vocab.itos[i] for i in y]\n",
        "      bleu_sum += bleu_score([translated], [[target]])\n",
        "    self.log('average_bleu_score', bleu_sum/len(batch), on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
        "    return ret\n",
        "  \n",
        "  def _step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    # the model generates token-by-token and 1st token <bos> is always known\n",
        "    # hence, the loss must be calculated between the input and 1-right shift of the output\n",
        "    y_shifted, target_pred = y[:-1,:], y[1:,:]\n",
        "    # create masks\n",
        "    x_mask, y_mask, x_padding_mask, y_padding_mask = self.create_masks(x, y_shifted)\n",
        "    # predict\n",
        "    pred = self(x, y_shifted, x_mask, y_mask, x_padding_mask, y_padding_mask, x_padding_mask)\n",
        "    # calc loss\n",
        "    a = pred.reshape(-1, pred.shape[-1])\n",
        "    b = target_pred.reshape(-1)\n",
        "    loss = torch.nn.functional.cross_entropy(a, b, ignore_index=self.params.target.pad_idx)\n",
        "    return {'loss': loss}\n",
        "  \n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.Adam(self.parameters(), lr=self.params.learning_rate)\n",
        "    return optimizer\n",
        "\n",
        "# Sample model training\n",
        "sample_model = Transformer_Model(Transformer_Model.Parameters(\n",
        "    src=Transformer_Model.Parameters.LangParams(\n",
        "        vocab=EN_VOCAB,\n",
        "        max_seq_length=en_max_seq_length,\n",
        "        pad_idx=PAD_IDX,\n",
        "        bos_idx=BOS_IDX,\n",
        "        eos_idx=EOS_IDX,\n",
        "    ),\n",
        "    target=Transformer_Model.Parameters.LangParams(\n",
        "        vocab=HI_VOCAB,\n",
        "        max_seq_length=hi_max_seq_length,\n",
        "        pad_idx=PAD_IDX,\n",
        "        bos_idx=BOS_IDX,\n",
        "        eos_idx=EOS_IDX,\n",
        "    ),\n",
        "    encoder_layers=1,\n",
        "    decoder_layers=1,\n",
        "    embedding_dim=128,\n",
        "))\n",
        "\n",
        "# This will print gibberish\n",
        "from torchmetrics.functional import bleu_score\n",
        "sample_translation = sample_model.translate(\"It's not the President.\", en_tokenizer, max_tokens=10)\n",
        "log('Sample src sentence', \"It's not the President.\")\n",
        "log('Sample translation (not trained yet)', sample_translation)\n",
        "log('Sample translation BLEU score(not trained yet)', bleu_score([inltk.tokenize(sample_translation, LANG_TARGET)], [[[\"▁यह\", \"▁राष्ट्रपति\", \"▁नहीं\", \"▁है\", \"।\"]]]))\n",
        "\n",
        "# Show sample model\n",
        "sample_model\n",
        "\n",
        "# sample_trainer = pl.Trainer(\n",
        "#     max_epochs=1,\n",
        "# )\n",
        "# sample_trainer.fit(sample_model, sample_datamodule)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample src sentence: \u001b[1;35mIt's not the President.\u001b[0m\n",
            "Sample translation (not trained yet): \u001b[1;35m लोभ ऋतु माइल मीठे St0% विस् वायुसेना प्राचार्य आन\u001b[0m\n",
            "Sample translation BLEU score(not trained yet): \u001b[1;35m0.0\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer_Model(\n",
              "  (enc): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dec): TransformerDecoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (gen): Linear(in_features=128, out_features=20782, bias=True)\n",
              "  (src_emb): Token_Embedding(\n",
              "    (emb): Embedding(35970, 128)\n",
              "  )\n",
              "  (target_emb): Token_Embedding(\n",
              "    (emb): Embedding(20782, 128)\n",
              "  )\n",
              "  (pos_emb): Positional_Embedding(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKSTd_oTpy8f"
      },
      "source": [
        "### Show mlflow tracking webpage\n",
        "\n",
        "All logs generated by the below training cell are shown on this page. It also stores data from all historical runs. Due to some bugs, this doesn't allow me to assign names to runs yet but every run is recorded and the performance of previous runs can be seen.\n",
        "\n",
        "**NOTE:** Right click inside the IFrame and click `Reload Frame` to see new runs.\n",
        "\n",
        "**OR:** Click on the `Experiments` tab to refresh the list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lIj1O3tzn34X",
        "outputId": "8109f7d2-30cc-4902-85bb-3e16bcc8db98"
      },
      "source": [
        "%%html\n",
        "<div width=\"-webkit-fill-available\">\n",
        "  <iframe src=\"https://dagshub.com/jaideepheer/CSL7340-NLP.Project/experiments/\" width=\"100%\" height=\"1024\"></iframe>\n",
        "</div>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div width=\"-webkit-fill-available\">\n",
              "  <iframe src=\"https://dagshub.com/jaideepheer/CSL7340-NLP.Project/experiments/\" width=\"100%\" height=\"1024\"></iframe>\n",
              "</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-IvOWE7n2NY"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KH5W1vzt_YD",
        "outputId": "9add7365-0a5a-47c8-ae4d-7a5d3bb00322"
      },
      "source": [
        "# Hyperparamaters\n",
        "@dataclass(frozen=True)\n",
        "class Hyperparamaters:\n",
        "  max_epochs: int = 100\n",
        "  learning_rate: float = 1e-3\n",
        "  # https://blog.ml.cmu.edu/2020/03/20/are-sixteen-heads-really-better-than-one/\n",
        "  attention_heads: int = 8\n",
        "  encoder_layers: int = 8\n",
        "  decoder_layers: int = 8\n",
        "  linear_dim: int = 128\n",
        "  dropout: float = 0.1\n",
        "  embedding_dim: int = 128\n",
        "  batch_size: int = 32\n",
        "  test_size_ratio: float = 0.2\n",
        "  val_size_ratio: float = 0.1\n",
        "  logs_per_batch: int = 8 # Higher values may slow down overall training.\n",
        "  check_val_every_n_epoch: int = 10 # Validation is very slow due to bleu score calculation\n",
        "  en_max_seq_length: int = en_max_seq_length\n",
        "  hi_max_seq_length: int = hi_max_seq_length\n",
        "\n",
        "hyper_params = Hyperparamaters()\n",
        "assert hyper_params.batch_size%hyper_params.logs_per_batch == 0\n",
        "\n",
        "# Create datamodule\n",
        "datamodule = BatchingDataModule(\n",
        "    BatchingDataModule.Parameters(\n",
        "        src=BatchingDataModule.Parameters.LangParams(\n",
        "            data=DATA['en_tok'],\n",
        "            vocab=EN_VOCAB,\n",
        "            pad_idx=PAD_IDX,\n",
        "            bos_idx=BOS_IDX,\n",
        "            eos_idx=EOS_IDX,\n",
        "        ),\n",
        "        target=BatchingDataModule.Parameters.LangParams(\n",
        "            data=DATA['hi_tok'],\n",
        "            vocab=HI_VOCAB,\n",
        "            pad_idx=PAD_IDX,\n",
        "            bos_idx=BOS_IDX,\n",
        "            eos_idx=EOS_IDX,\n",
        "        ),\n",
        "        batch_size=hyper_params.batch_size,\n",
        "        test_size_ratio=hyper_params.test_size_ratio,\n",
        "        val_size_ratio=hyper_params.val_size_ratio,\n",
        "    )\n",
        ")\n",
        "\n",
        "# Define logger params\n",
        "# https://mlflow.org/docs/latest/python_api/mlflow.pytorch.html#module-mlflow.pytorch\n",
        "# https://stackoverflow.com/questions/61615818/setting-up-mlflow-on-google-colab\n",
        "from pytorch_lightning.loggers import MLFlowLogger\n",
        "import mlflow, mlflow.pytorch, os\n",
        "from mlflow.tracking import MlflowClient\n",
        "os.environ['MLFLOW_TRACKING_PASSWORD'] = '97d09c6f4b6c8a0753f27cc64b501eb83f82a2cb'\n",
        "os.environ['MLFLOW_TRACKING_USERNAME'] = 'jaideepheer'\n",
        "os.environ['MLFLOW_TRACKING_URI'] = 'https://dagshub.com/jaideepheer/CSL7340-NLP.Project.mlflow'\n",
        "mlflow.set_tracking_uri(os.environ['MLFLOW_TRACKING_URI'])\n",
        "\n",
        "# Create experiment\n",
        "experiment_name = \"Transformer Model\"\n",
        "# mlflow.create_experiment(experiment_name)\n",
        "mlflow.set_experiment(experiment_name)\n",
        "\n",
        "# Setup checkpointing\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "checkpoint_callbacks = [\n",
        "  ModelCheckpoint(\n",
        "    monitor='loss',\n",
        "    dirpath=PATH['workdir_save'] / 'training_checkpoint_dir',\n",
        "    filename='transformer_model-{epoch:02d}-{loss:.2f}',\n",
        "    save_top_k=3,\n",
        "    mode='min',\n",
        "  ),\n",
        "  # ModelCheckpoint(\n",
        "  #   monitor='val_loss',\n",
        "  #   dirpath=PATH['workdir_save'] / 'training_checkpoint_dir',\n",
        "  #   filename='transformer_model-{epoch:02d}-{val_loss:.2f}',\n",
        "  #   save_top_k=3,\n",
        "  #   mode='min',\n",
        "  # ),\n",
        "]\n",
        "\n",
        "# Create logger\n",
        "logger = MLFlowLogger(\n",
        "  experiment_name=experiment_name,\n",
        "  tracking_uri=os.environ['MLFLOW_TRACKING_URI'],\n",
        "  # tags=tags,\n",
        "  # prefix=key,\n",
        ")\n",
        "\n",
        "# Log hyperparams\n",
        "logger.log_hyperparams(asdict(hyper_params))\n",
        "\n",
        "# Define trainer\n",
        "trainer = pl.Trainer(\n",
        "    gpus=-1, # Use all GPUs\n",
        "    precision=16, # Use 16bit precission for larger batches and faster training\n",
        "    max_epochs=hyper_params.max_epochs,\n",
        "    logger=logger,\n",
        "    log_every_n_steps=hyper_params.batch_size/hyper_params.logs_per_batch,\n",
        "    check_val_every_n_epoch=hyper_params.check_val_every_n_epoch,\n",
        "    # profiler=\"simple\", \n",
        "    progress_bar_refresh_rate=20,\n",
        "    # dir to save checkpoints\n",
        "    callbacks=[*checkpoint_callbacks],\n",
        ")\n",
        "\n",
        "# Create model\n",
        "model = Transformer_Model(Transformer_Model.Parameters(\n",
        "    src=Transformer_Model.Parameters.LangParams(\n",
        "        vocab=EN_VOCAB,\n",
        "        max_seq_length=hyper_params.en_max_seq_length,\n",
        "        pad_idx=PAD_IDX,\n",
        "        bos_idx=BOS_IDX,\n",
        "        eos_idx=EOS_IDX,\n",
        "    ),\n",
        "    target=Transformer_Model.Parameters.LangParams(\n",
        "        vocab=HI_VOCAB,\n",
        "        max_seq_length=hyper_params.hi_max_seq_length,\n",
        "        pad_idx=PAD_IDX,\n",
        "        bos_idx=BOS_IDX,\n",
        "        eos_idx=EOS_IDX,\n",
        "    ),\n",
        "    encoder_layers=hyper_params.encoder_layers,\n",
        "    decoder_layers=hyper_params.decoder_layers,\n",
        "    embedding_dim=hyper_params.embedding_dim,\n",
        "    learning_rate=hyper_params.learning_rate,\n",
        "    attention_heads=hyper_params.attention_heads,\n",
        "    linear_dim=hyper_params.linear_dim,\n",
        "    dropout=hyper_params.dropout,\n",
        "))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning: Checkpoint directory gdrive/MyDrive/Classroom/CSL7340 - Natural Language Processing (Reg.)/NLP Project/workdir_save/training_checkpoint_dir exists and is not empty.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "Using native 16bit precision.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452,
          "referenced_widgets": [
            "98cb238bcbda49d1b9632e4036ed8077",
            "464cb792fd874834be3a17848b86f4eb",
            "cb92a60b0d5145059ec0c68337f063f8",
            "8e11b02357684477a460fbfc4dac6f96",
            "a6890e4cb78b4f9aaa4fdcc94775f213",
            "967142ebbfa64523b190337520cc9651",
            "c8154ecc6e574871b3ef64fd3315d3d4",
            "f75c97de010a42f6b95353aabaed98de",
            "46b9a1bd92e6465da8d73351c51fd2f1",
            "09632bb274c54bd5ab154e95b148a074",
            "3091133dab2e4e93bb2b78f19c317f99",
            "e6fd8c0c2002436cbf249edfbfd45501",
            "b7782a6d04a745ba9a2522b08eb8bfca",
            "997b73c22e99463ab717438d0901d09f",
            "38cbc2cf830a45fc8f41da2ed9b11f28",
            "77d4ef615270431b8e5b818851b9b3a3",
            "6af0a4f62bd44e2da09713d17a60c4a5",
            "2b4e7d4d404a4fb29b4eb15e46498bf2",
            "e9c44ec8eb1b423eb3d6a7ad0baa5da9",
            "b35e44d477c744309d3549b88539d663",
            "f34a54c2a5c44d16b6bcd93b564c593f",
            "c9cb17b4abc24b7489d5aa7c4a4071b8",
            "40b5f25042ff474d999017b1872ebe84",
            "c31bc5687d9b4a2caf6bd68805fad2be",
            "73070c5fadea4dba9d78afb7ba726776",
            "ae4463263cbd45e08e3aa4347d299de6",
            "009506918195482ebf07558219d9afec",
            "0493c73ea5b442e58197e61e59947836",
            "6c652b01bd104160a22eb156ca05679e",
            "3ba21c40419e4bfa9462a6577af1d6ca",
            "51f4ffd3797547348e12f25c65c7221d",
            "05f1cf6660974640bf14a875bfb2e8ed",
            "ad0fa287d9004e93a0cd0a52cf2823cb",
            "7eca50030fe548c6b441ec77c0b42645",
            "a1cd54ed267c40fdbc01c5ad0204c9fa",
            "ba69a8276c8d40e3be558cdc05c2abd8",
            "203692acabf1495a95488b39e18d703e",
            "ef7e89fa5f954f97ab6f241bc669aa7d",
            "f620ccd9997a495d8a2388a845a02ff1",
            "df65cf7703cd469ebf72c2d785a38371"
          ]
        },
        "id": "Zx4gBrQJoZRi",
        "outputId": "8905757e-dd9f-44bc-da39-11a691206fae"
      },
      "source": [
        "# Fit model\n",
        "trainer.fit(model, datamodule)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning: Checkpoint directory gdrive/MyDrive/Classroom/CSL7340 - Natural Language Processing (Reg.)/NLP Project/workdir_save/training_checkpoint_dir exists and is not empty.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "Using native 16bit precision.\n",
            "\n",
            "  | Name       | Type                 | Params\n",
            "----------------------------------------------------\n",
            "0 | enc        | TransformerEncoder   | 796 K \n",
            "1 | dec        | TransformerDecoder   | 1.3 M \n",
            "2 | gen        | Linear               | 2.7 M \n",
            "3 | src_emb    | Token_Embedding      | 4.6 M \n",
            "4 | target_emb | Token_Embedding      | 2.7 M \n",
            "5 | pos_emb    | Positional_Embedding | 0     \n",
            "----------------------------------------------------\n",
            "12.1 M    Trainable params\n",
            "0         Non-trainable params\n",
            "12.1 M    Total params\n",
            "48.276    Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98cb238bcbda49d1b9632e4036ed8077",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46b9a1bd92e6465da8d73351c51fd2f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6af0a4f62bd44e2da09713d17a60c4a5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73070c5fadea4dba9d78afb7ba726776",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad0fa287d9004e93a0cd0a52cf2823cb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n0W4QfpuepR"
      },
      "source": [
        "### Load model from checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn3_8XtiueQz",
        "outputId": "7e7190b8-88a0-460a-b316-a090f5346c80"
      },
      "source": [
        "checkpoint = Transformer_Model.load_from_checkpoint(\n",
        "    PATH['workdir_save'] / 'training_checkpoint_dir' / 'transformer_model-epoch=09-loss=9.07.ckpt',\n",
        "    params=Transformer_Model.Parameters(\n",
        "    src=Transformer_Model.Parameters.LangParams(\n",
        "        vocab=EN_VOCAB,\n",
        "        max_seq_length=hyper_params.en_max_seq_length,\n",
        "        pad_idx=PAD_IDX,\n",
        "        bos_idx=BOS_IDX,\n",
        "        eos_idx=EOS_IDX,\n",
        "    ),\n",
        "    target=Transformer_Model.Parameters.LangParams(\n",
        "        vocab=HI_VOCAB,\n",
        "        max_seq_length=hyper_params.hi_max_seq_length,\n",
        "        pad_idx=PAD_IDX,\n",
        "        bos_idx=BOS_IDX,\n",
        "        eos_idx=EOS_IDX,\n",
        "    ),\n",
        "    encoder_layers=hyper_params.encoder_layers,\n",
        "    decoder_layers=hyper_params.decoder_layers,\n",
        "    embedding_dim=hyper_params.embedding_dim,\n",
        "    learning_rate=hyper_params.learning_rate,\n",
        "    attention_heads=hyper_params.attention_heads,\n",
        "    linear_dim=hyper_params.linear_dim,\n",
        "    dropout=hyper_params.dropout,\n",
        "  )\n",
        ")\n",
        "checkpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer_Model(\n",
              "  (enc): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (4): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (5): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (6): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (7): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dec): TransformerDecoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (4): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (5): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (6): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (7): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (gen): Linear(in_features=128, out_features=20782, bias=True)\n",
              "  (src_emb): Token_Embedding(\n",
              "    (emb): Embedding(35970, 128)\n",
              "  )\n",
              "  (target_emb): Token_Embedding(\n",
              "    (emb): Embedding(20782, 128)\n",
              "  )\n",
              "  (pos_emb): Positional_Embedding(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysyupTiZONRm"
      },
      "source": [
        "### Show translation samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11uFHFaFOQBX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976,
          "referenced_widgets": [
            "2a01d86dd667476bb09359afdbb8a8a6",
            "6973e382c56f48d3bfb1431bc58acf0d",
            "d5ededb0b6714ee282f2278359ca87d2",
            "a910807d73e0470f87db585bf94c0887",
            "fec37da9e920414ca6c3a3ffec7dacab",
            "2e2db264564b4361b6eb30c3ccaf12a7",
            "674a4150e7d74c14a188ee5d5251ed72",
            "0d610ad2f51645cb90e84a49b47bd103"
          ]
        },
        "outputId": "d5f8e6f6-23f1-46fb-c5f0-e4a36ae94fad"
      },
      "source": [
        "num_samples = 30\n",
        "\n",
        "SAMPLE_DATA = DATA[['en', 'hi', 'hi_tok']].sample(n=num_samples)\n",
        "\n",
        "# Translate\n",
        "tr = []\n",
        "tr_tok = []\n",
        "for idx, row in tqdm(SAMPLE_DATA.iterrows(), total=len(SAMPLE_DATA)):\n",
        "  en_sen, hi_sen = row['en'], row['hi_tok']\n",
        "  tr.append(checkpoint.translate(en_sen, en_tokenizer, max_tokens=len(hi_sen)))\n",
        "  tr_tok.append(inltk.tokenize(tr[-1], LANG_TARGET))\n",
        "SAMPLE_DATA['translated'] = tr\n",
        "\n",
        "# Calculate bleu score on sample data\n",
        "from torchmetrics.functional import bleu_score\n",
        "log('Mean BLEU score (in sample)', bleu_score(tr_tok, [[i] for i in SAMPLE_DATA['hi_tok']]))\n",
        "\n",
        "SAMPLE_DATA[['en', 'hi', 'translated']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a01d86dd667476bb09359afdbb8a8a6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Mean BLEU score (in sample): \u001b[1;35m0.0\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>hi</th>\n",
              "      <th>translated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3041</th>\n",
              "      <td>So, in this case the samples is a partition th...</td>\n",
              "      <td>इसलिए, इस मामले में नमूने एक विभाजन है जो हमार...</td>\n",
              "      <td>कहा कि कहा कि कहा कि कि कि कि के के कहा के कि...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3911</th>\n",
              "      <td>I am truly grateful to Salman.</td>\n",
              "      <td>मैं सलमान की बहुत इज्जत करती हूं।</td>\n",
              "      <td>मैं मैं मैं है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11022</th>\n",
              "      <td>NITI Aayog has taken steps to ensure that thes...</td>\n",
              "      <td>नीति आयोग ने यह सुनिश्चित करने के लिए कदम उठाए...</td>\n",
              "      <td>उन्होंने ने ने के के के के के के के के के के ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9173</th>\n",
              "      <td>The official orders will be issued soon, offic...</td>\n",
              "      <td>अधिकारियों ने कहा कि आधिकारिक आदेश जल्द आएगा।</td>\n",
              "      <td>इस ने ने के के। के। के</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13044</th>\n",
              "      <td>Members &amp; workers of Congress protest across t...</td>\n",
              "      <td>कर्नाटक में बीएस येदियुरप्पा को सरकार बनाने के...</td>\n",
              "      <td>उन्होंने ने के के के के के के के के के के के ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23345</th>\n",
              "      <td>or cause the streams in your garden to disappe...</td>\n",
              "      <td>उसका पानी नीचे उतर (के खुश्क) हो जाए फिर तो उस...</td>\n",
              "      <td>, के के है के है है है है है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10029</th>\n",
              "      <td>Following this there were skirmishes between t...</td>\n",
              "      <td>इसके बाद दोनों टीमों के बीच जमकर गोलियां चलीं.</td>\n",
              "      <td>इस के में के के के के।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24607</th>\n",
              "      <td>Sowing of Jute and Mesta is also in progress.</td>\n",
              "      <td>जूट और मेस्टा की बुवाई भी प्रगति पर है।</td>\n",
              "      <td>यह और और और और और और और और और।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5417</th>\n",
              "      <td>If the level...</td>\n",
              "      <td>अगर तह में .</td>\n",
              "      <td>यह  के</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13503</th>\n",
              "      <td>Raveena Tandon and husband Anil Thadani</td>\n",
              "      <td>रवीना टंडन और पति अनिल थडानी में होने जा रही ह...</td>\n",
              "      <td>इस और और और और और और और</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18259</th>\n",
              "      <td>The President of India, Shri Pranab Mukherjee ...</td>\n",
              "      <td>भारत के राष्ट्रपति श्री प्रणव मुखर्जी ने आज (9...</td>\n",
              "      <td>ने  ((((() (())((())((((()))</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3422</th>\n",
              "      <td>Science is one of the most important inputs in...</td>\n",
              "      <td>आधुनिक युद्व और रक्षा युद्वनीति में विज्ञान एक...</td>\n",
              "      <td>और के के के के के के के के के के के</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22607</th>\n",
              "      <td>During the last 24 hours more than 94 thousand...</td>\n",
              "      <td>पिछले 24 घंटों के दौरान 72 हजार नौ सौ 39 से अध...</td>\n",
              "      <td>इस के के के के के के के के के के के।। के के</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12575</th>\n",
              "      <td>These middlemen used to siphon off billions of...</td>\n",
              "      <td>ये बिचौलिये अरबों-खरबों रुपया निकाल देते थे और...</td>\n",
              "      <td>उन्होंने के के के के के के के के के के के के ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4501</th>\n",
              "      <td>Eggs are nutritious and are low in calories.</td>\n",
              "      <td>अंडे काफी हेल्दी होते हैं जिनमें कैलोरी कम होत...</td>\n",
              "      <td>इस में और और और</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>Pradhan Mantri Awas Yojana is a programme to p...</td>\n",
              "      <td>प्रधानमंत्री आवास योजना 2022 तक सभी को किफायती...</td>\n",
              "      <td>के के के के, के के के के के के, के, और के, औ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4649</th>\n",
              "      <td>Both the leaders were alleged to be in touch w...</td>\n",
              "      <td>दोनों नेताओं पर भारतीय जनता पार्टी के नेताओं क...</td>\n",
              "      <td>कांग्रेस ने के के के के के के के के के के के ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10505</th>\n",
              "      <td>JNPT or Jawaharlal Nehru Port Trust is the lar...</td>\n",
              "      <td>जवाहर लाल नेहरू पोर्ट ट्रस्ट (जेएनपीटी) भारत म...</td>\n",
              "      <td>भारत के के के के के के के के के के</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14615</th>\n",
              "      <td>Finally, a person from the Hindu community pro...</td>\n",
              "      <td>आखिर में हिंदू समुदाय के एक व्यक्ति ने बेटी का...</td>\n",
              "      <td>उन्होंने के के के के के के के के के के के के ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17296</th>\n",
              "      <td>\"\"\"On many occasions, Rahul Gandhi had categor...</td>\n",
              "      <td>उन्होंने यह भी कहा कि कई मौकों पर राहुल गांधी ...</td>\n",
              "      <td>ने ने ने ने ने ने के ने ने ने के के के के के</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6668</th>\n",
              "      <td>This may require descaling with acids for whic...</td>\n",
              "      <td>इसे क्षार (एसिड) द्वारा साफ करने की जरूरत होती...</td>\n",
              "      <td>यह के के के के के के है के है है है है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19340</th>\n",
              "      <td>That gives happiness.</td>\n",
              "      <td>इससे खुशी मिलती है।</td>\n",
              "      <td>यह में है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>Alia Bhatt took to her Instagram page and shar...</td>\n",
              "      <td>शाहीन भट्ट का बर्थडे सेलिब्रेट करने के लिए आलि...</td>\n",
              "      <td>इस के के के के के के के और के के और के और और ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12152</th>\n",
              "      <td>The driver was also injured in the accident.</td>\n",
              "      <td>हादसे में चालक भी घायल हो गया है.</td>\n",
              "      <td>इस में में में में में में में</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9409</th>\n",
              "      <td>Earlier in the day, Congress spokesperson Rand...</td>\n",
              "      <td>बीच में ही कांग्रेस प्रवक्‍ता रणदीप सिंह सुरजे...</td>\n",
              "      <td>उन्होंने ने ने ने ने ने के के के के ने के के ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1357</th>\n",
              "      <td>Later that very Passover night, the apostles a...</td>\n",
              "      <td>फसह की उसी रात, प्रेरित एक बार फिर आपस में बहस...</td>\n",
              "      <td>यह के के के के के के के के के के के के के के के</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7802</th>\n",
              "      <td>You are not a bird.</td>\n",
              "      <td>तू चिड़िया है क्या?</td>\n",
              "      <td>नहीं नहीं नहीं नहीं</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18456</th>\n",
              "      <td>He also stole three bags having gold kept in i...</td>\n",
              "      <td>उन्होंने लॉकर से उसमें रखे सोने के तीन बैग भी ...</td>\n",
              "      <td>उन्होंने ने के के के के के के के के के के के</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4723</th>\n",
              "      <td>He later switched off his mobile phone.</td>\n",
              "      <td>बाद में उसने अपना मोबाइल भी बंद कर दिया।</td>\n",
              "      <td>इस के के में के के में</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20069</th>\n",
              "      <td>We have launched several welfare schemes for t...</td>\n",
              "      <td>हमने वंचित वर्गों के लिए कई कल्याणकारी योजनाएं...</td>\n",
              "      <td>उन्होंने के के के के है है के है</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      en  ...                                         translated\n",
              "3041   So, in this case the samples is a partition th...  ...   कहा कि कहा कि कहा कि कि कि कि के के कहा के कि...\n",
              "3911                      I am truly grateful to Salman.  ...                                     मैं मैं मैं है\n",
              "11022  NITI Aayog has taken steps to ensure that thes...  ...   उन्होंने ने ने के के के के के के के के के के ...\n",
              "9173   The official orders will be issued soon, offic...  ...                             इस ने ने के के। के। के\n",
              "13044  Members & workers of Congress protest across t...  ...   उन्होंने ने के के के के के के के के के के के ...\n",
              "23345  or cause the streams in your garden to disappe...  ...                       , के के है के है है है है है\n",
              "10029  Following this there were skirmishes between t...  ...                             इस के में के के के के।\n",
              "24607      Sowing of Jute and Mesta is also in progress.  ...                     यह और और और और और और और और और।\n",
              "5417                                     If the level...  ...                                             यह  के\n",
              "13503            Raveena Tandon and husband Anil Thadani  ...                            इस और और और और और और और\n",
              "18259  The President of India, Shri Pranab Mukherjee ...  ...                       ने  ((((() (())((())((((()))\n",
              "3422   Science is one of the most important inputs in...  ...                और के के के के के के के के के के के\n",
              "22607  During the last 24 hours more than 94 thousand...  ...        इस के के के के के के के के के के के।। के के\n",
              "12575  These middlemen used to siphon off billions of...  ...   उन्होंने के के के के के के के के के के के के ...\n",
              "4501        Eggs are nutritious and are low in calories.  ...                                    इस में और और और\n",
              "194    Pradhan Mantri Awas Yojana is a programme to p...  ...    के के के के, के के के के के के, के, और के, औ...\n",
              "4649   Both the leaders were alleged to be in touch w...  ...   कांग्रेस ने के के के के के के के के के के के ...\n",
              "10505  JNPT or Jawaharlal Nehru Port Trust is the lar...  ...                 भारत के के के के के के के के के के\n",
              "14615  Finally, a person from the Hindu community pro...  ...   उन्होंने के के के के के के के के के के के के ...\n",
              "17296  \"\"\"On many occasions, Rahul Gandhi had categor...  ...       ने ने ने ने ने ने के ने ने ने के के के के के\n",
              "6668   This may require descaling with acids for whic...  ...             यह के के के के के के है के है है है है\n",
              "19340                              That gives happiness.  ...                                          यह में है\n",
              "718    Alia Bhatt took to her Instagram page and shar...  ...   इस के के के के के के के और के के और के और और ...\n",
              "12152       The driver was also injured in the accident.  ...                     इस में में में में में में में\n",
              "9409   Earlier in the day, Congress spokesperson Rand...  ...   उन्होंने ने ने ने ने ने के के के के ने के के ...\n",
              "1357   Later that very Passover night, the apostles a...  ...    यह के के के के के के के के के के के के के के के\n",
              "7802                                 You are not a bird.  ...                                नहीं नहीं नहीं नहीं\n",
              "18456  He also stole three bags having gold kept in i...  ...       उन्होंने ने के के के के के के के के के के के\n",
              "4723             He later switched off his mobile phone.  ...                             इस के के में के के में\n",
              "20069  We have launched several welfare schemes for t...  ...                   उन्होंने के के के के है है के है\n",
              "\n",
              "[30 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372,
          "referenced_widgets": [
            "50f740a077094951a8036d1720bd629c",
            "70d83ceaad2c4033953b057afefe029a",
            "9adee940e7784fcfbed5a98c56d6bc1a",
            "b78e4e0a35ec46cab677cdfe123fe65c",
            "8679474ce34941afaea1dec2bed7df73",
            "ffaff9fffba345d3bf40d1764ea73a87",
            "cf816b5732ef403ab4914d31b3c312bb",
            "d7d5fe938242429eaece9a853b005b1c"
          ]
        },
        "id": "IVzb2HaD0a5S",
        "outputId": "316419df-3870-4e42-a450-07acc3a3a133"
      },
      "source": [
        "# Selected samples\n",
        "selected_samples = [12396, 1181, 21541, 24163, 11939, 4350, 11572, 10689, 18456]\n",
        "\n",
        "# Show select samples\n",
        "SAMPLE_DATA = DATA[['en', 'hi', 'hi_tok']].iloc[selected_samples]\n",
        "\n",
        "# Translate\n",
        "tr = []\n",
        "tr_tok = []\n",
        "for idx, row in tqdm(SAMPLE_DATA.iterrows(), total=len(SAMPLE_DATA)):\n",
        "  en_sen, hi_sen = row['en'], row['hi_tok']\n",
        "  tr.append(checkpoint.translate(en_sen, en_tokenizer, max_tokens=len(hi_sen)))\n",
        "  tr_tok.append(inltk.tokenize(tr[-1], LANG_TARGET))\n",
        "SAMPLE_DATA['translated'] = tr\n",
        "\n",
        "# Calculate bleu score on sample data\n",
        "from torchmetrics.functional import bleu_score\n",
        "log('Mean BLEU score (in sample)', bleu_score(tr_tok, [[i] for i in SAMPLE_DATA['hi_tok']]))\n",
        "\n",
        "SAMPLE_DATA[['en', 'hi', 'translated']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50f740a077094951a8036d1720bd629c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Mean BLEU score (in sample): \u001b[1;35m0.0\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>hi</th>\n",
              "      <th>translated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12396</th>\n",
              "      <td>But it never rings.</td>\n",
              "      <td>लेकिन इससे कभी भी जूलरी नहीं बनती.</td>\n",
              "      <td>उन्होंने कहा नहीं नहीं</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1181</th>\n",
              "      <td>In Rajasthan Assembly Elections, Congress got ...</td>\n",
              "      <td>वहीं, जम्मू-कश्मीर की 6 सीटों में से 3 बीजेपी ...</td>\n",
              "      <td>मुख्यमंत्री ने ने ने के ने के के के के के के</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21541</th>\n",
              "      <td>He said government has failed to</td>\n",
              "      <td>उन्होंने कहा कि सरकार दीनदयाल</td>\n",
              "      <td>सरकार सरकार सरकार सरकार सरकार</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24163</th>\n",
              "      <td>He further said that the State has been given ...</td>\n",
              "      <td>उन्होंने यह भी कहा कि बीमारी की जल्दी चेतावनी ...</td>\n",
              "      <td>उन्होंने ने के के के के के के के के के के के ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11939</th>\n",
              "      <td>Take a look at these.</td>\n",
              "      <td>नजर डालें इन्हीं पर।</td>\n",
              "      <td>इस में है में है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4350</th>\n",
              "      <td>The recovery rate among COVID-19 patients has ...</td>\n",
              "      <td>भारत में कोविड-19 रिकवरी दर भी लगातार बढ़ रही ...</td>\n",
              "      <td>इस के के के के</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11572</th>\n",
              "      <td>She said her merger proposal was accepted by P...</td>\n",
              "      <td>सुषमा ने कहा कि उनके इस विलय प्रस्ताव को प्रधा...</td>\n",
              "      <td>प्रधानमंत्री मोदी ने मोदी के ने के मोदी मोदी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10689</th>\n",
              "      <td>Samajwadi party will fight the Lik Sabha elect...</td>\n",
              "      <td>कांग्रेस पार्टी उत्तरप्रदेश विधानसभा में चुनाव...</td>\n",
              "      <td>भाजपा ने के के के के के के के के के</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18456</th>\n",
              "      <td>He also stole three bags having gold kept in i...</td>\n",
              "      <td>उन्होंने लॉकर से उसमें रखे सोने के तीन बैग भी ...</td>\n",
              "      <td>उन्होंने उन्होंने ने के के के के के के के के के</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      en  ...                                         translated\n",
              "12396                                But it never rings.  ...                             उन्होंने कहा नहीं नहीं\n",
              "1181   In Rajasthan Assembly Elections, Congress got ...  ...       मुख्यमंत्री ने ने ने के ने के के के के के के\n",
              "21541                   He said government has failed to  ...                      सरकार सरकार सरकार सरकार सरकार\n",
              "24163  He further said that the State has been given ...  ...   उन्होंने ने के के के के के के के के के के के ...\n",
              "11939                              Take a look at these.  ...                                   इस में है में है\n",
              "4350   The recovery rate among COVID-19 patients has ...  ...                                     इस के के के के\n",
              "11572  She said her merger proposal was accepted by P...  ...       प्रधानमंत्री मोदी ने मोदी के ने के मोदी मोदी\n",
              "10689  Samajwadi party will fight the Lik Sabha elect...  ...                भाजपा ने के के के के के के के के के\n",
              "18456  He also stole three bags having gold kept in i...  ...    उन्होंने उन्होंने ने के के के के के के के के के\n",
              "\n",
              "[9 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    }
  ]
}